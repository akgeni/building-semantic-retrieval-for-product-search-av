{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0861a985-76f5-4df8-9d9c-23c5a7b11d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, util, models, losses, InputExample\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import gzip\n",
    "import os\n",
    "import tarfile\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import pickle\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "#### Just some code to print debug information to stdout\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\", level=logging.INFO, handlers=[LoggingHandler()]\n",
    ")\n",
    "#### /print debug information to stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f97b125f-101e-48db-a56e-26291a9a681b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args(train_batch_size=128, max_seq_length=300, model_name='sentence-transformers/all-MiniLM-L12-v2', max_passages=0, epochs=2, pooling='mean', negs_to_use=None, warmup_steps=1000, lr=4e-05, num_negs_per_system=5, use_pre_trained_model=(False,), use_all_queries=(False,), ce_score_margin=3.0)\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Args():\n",
    "    train_batch_size: int = 128\n",
    "    max_seq_length: int = 300\n",
    "    model_name: str = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
    "    max_passages:int = 0\n",
    "    epochs: int = 2\n",
    "    pooling: str = \"mean\"\n",
    "    negs_to_use: str = None\n",
    "    warmup_steps: int = 1000\n",
    "    lr: float = 4e-5\n",
    "    num_negs_per_system: int = 5\n",
    "    use_pre_trained_model: bool = False,\n",
    "    use_all_queries: bool = False,\n",
    "    ce_score_margin: float = 3.0\n",
    "\n",
    "print(Args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c4e44ad-e77b-40b0-8de3-d00e3802f2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sentence-transformers/all-MiniLM-L12-v2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = Args()\n",
    "model_name = args.model_name\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e15ce14f-02e7-4fa6-b2b2-f613717f6476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increasing the train batch size improves the model performance, but requires more GPU memory\n",
    "train_batch_size = (\n",
    "    args.train_batch_size\n",
    ")\n",
    "max_seq_length = args.max_seq_length  # Max length for passages. Increasing it, requires more GPU memory\n",
    "ce_score_margin = args.ce_score_margin  # Margin for the CrossEncoder score between negative and positive passages\n",
    "num_negs_per_system = (\n",
    "    args.num_negs_per_system\n",
    ")  # We used different systems to mine hard negatives. Number of hard negatives to add from each system\n",
    "num_epochs = args.epochs  # Number of epochs we want to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25eb228b-7446-4f8d-aa88-874e5e2edfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-17 06:30:11 - Create new SBERT model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-17 06:30:11 - Use pytorch device_name: cuda\n"
     ]
    }
   ],
   "source": [
    "# Load our embedding model\n",
    "\n",
    "logging.info(\"Create new SBERT model\")\n",
    "word_embedding_model = models.Transformer(model_name, max_seq_length=max_seq_length)\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), args.pooling)\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
    "\n",
    "model_save_path = \"output/train_bi-encoder-triplet-{}-{}\".format(\n",
    "    model_name.replace(\"/\", \"-\"), datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f15d52ff-90b0-484f-aae6-ed8fb05ff1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a custom MSMARCO dataset that returns triplets (query, positive, negative)\n",
    "# on-the-fly based on the information from the mined-hard-negatives jsonl file.\n",
    "from torch.utils.data import Dataset\n",
    "class MSMARCODataset(Dataset):\n",
    "    def __init__(self, query_pos_negs, queries_df, corpus):\n",
    "        self.queries_pos = dict(zip(list(query_pos_negs.query_id), list(query_pos_negs.pos_product_ids.apply(eval))))\n",
    "        self.queries_neg = dict(zip(list(query_pos_negs.query_id), list(query_pos_negs.neg_product_ids.apply(eval))))\n",
    "        self.queries_ids = list(query_pos_negs.query_id)\n",
    "        self.corpus = corpus\n",
    "        \n",
    "        self.item_dict = dict(zip(corpus.product_id, corpus.item_text))\n",
    "        self.queries = dict(zip(queries_df.query_id, queries_df[\"query\"]))\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        qid = self.queries_ids[item]\n",
    "        query_text = self.queries[qid]\n",
    "\n",
    "        pos_id = self.queries_pos[qid].pop()\n",
    "        pos_text = self.item_dict[pos_id]\n",
    "        self.queries_pos[qid].append(pos_id)\n",
    "\n",
    "        neg_id = self.queries_neg[qid].pop()\n",
    "        neg_text = self.item_dict[pos_id]\n",
    "        self.queries_neg[qid].append(neg_id)\n",
    "\n",
    "        return InputExample(texts=[query_text, pos_text, neg_text])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.queries_ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda301b5-d1da-4245-ad12-3f0ab8199fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## product info for given item\n",
    "def create_item_text(row):\n",
    "    title = row[\"product_title\"]\n",
    "    brand = row[\"product_brand\"]\n",
    "    color = row[\"product_color\"]\n",
    "    return f\"Title: {title}. Brand: {brand}. Color: {color}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42571d39-c968-4f74-a8a4-181606dc219e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_examles.shape (17060, 3)\n",
      "Size of corpus:  (1436116, 5)\n"
     ]
    }
   ],
   "source": [
    "esci = load_dataset(\"tasksource/esci\")\n",
    "\n",
    "\n",
    "training_examles = pd.read_csv(\"train_esci_pos_neg_top3_2024-06-10.csv\")\n",
    "print(\"training_examles.shape\", training_examles.shape)\n",
    "test_examples = pd.read_csv(\"test_esci_pos_neg_top3_2024-06-10.csv\")\n",
    "\n",
    "\n",
    "corpus_train = esci[\"train\"].to_pandas()\n",
    "corpus_product_train = corpus_train[[\"product_id\", \"product_title\", \"product_brand\", \"product_color\"]].drop_duplicates(subset=[\"product_id\"])\n",
    "\n",
    "corpus_query_train = corpus_train[[\"query_id\", \"query\"]].drop_duplicates(subset=[\"query_id\"])\n",
    "corpus_product_train['item_text'] = corpus_product_train.apply(lambda row: create_item_text(row), axis=1)\n",
    "\n",
    "\n",
    "print(\"Size of corpus: \", corpus_product_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3a899ba-6cdc-4898-b126-f856be06784e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MSMARCODataset(training_examles, corpus_query_train, corpus_product_train)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n",
    "#train_loss = losses.TripletLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5dc90bc-3e0c-4561-86cf-38b05968265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9083463b-3359-4af6-bf8b-f7cd2a110c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInformationRetrievalEvaluator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mqueries\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcorpus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mrelevant_docs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcorpus_chunk_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmrr_at_k\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mndcg_at_k\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0maccuracy_at_k\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprecision_recall_at_k\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmap_at_k\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mwrite_csv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtruncate_dim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mscore_functions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'cos_sim'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0mcos_sim\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x7f3a7ea671c0\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dot_score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mfunction\u001b[0m \u001b[0mdot_score\u001b[0m \u001b[0mat\u001b[0m \u001b[0;36m0x7f3a7ea67250\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmain_score_function\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "This class evaluates an Information Retrieval (IR) setting.\n",
       "\n",
       "Given a set of queries and a large corpus set. It will retrieve for each query the top-k most similar document. It measures\n",
       "Mean Reciprocal Rank (MRR), Recall@k, and Normalized Discounted Cumulative Gain (NDCG)\n",
       "\u001b[0;31mFile:\u001b[0m           /home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/sentence_transformers/evaluation/InformationRetrievalEvaluator.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation.InformationRetrievalEvaluator?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d255f787-89de-4490-a671-7ed6bbaada48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3966bdc0-3710-4811-ba26-31c69eef5d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca04c3a1-b94e-441c-8266-5e02e620e27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import evaluation\n",
    "\n",
    "# eval_df = pd.read_csv(\"eval_esci_exact.csv\")\n",
    "# eval_df = eval_df.dropna(subset=['query', 'product_title'], how='all')\n",
    "\n",
    "# eval_queries = eval_df[\"query\"].tolist()\n",
    "# eval_items = eval_df[\"product_title\"].tolist()\n",
    "# scores = [1.0]*len(eval_queries)\n",
    "# evaluator = evaluation.EmbeddingSimilarityEvaluator(eval_queries, eval_items, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72ee9ed4-4041-4f70-bf98-353bc621d8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import evaluation\n",
    "ir_eval_df = pd.read_csv(\"ir_eval_data.csv\").head(1000)\n",
    "ir_eval_df = ir_eval_df.dropna(subset=['query'], how='all')\n",
    "eval_queries = dict(zip(ir_eval_df.query_id.tolist(),ir_eval_df[\"query\"].tolist()))\n",
    "eval_relevant_docs = dict(zip(ir_eval_df.query_id.tolist(),[eval(x) for x in ir_eval_df[\"relevant_product_id\"].tolist()]))\n",
    "\n",
    "esci_test = esci[\"test\"].to_pandas()\n",
    "esci_test = esci_test.drop_duplicates(subset=[\"product_id\"])\n",
    "eval_corpus = dict(zip(esci_test.product_id.tolist(), esci_test[\"product_title\"].tolist()))\n",
    "\n",
    "evaluator = evaluation.InformationRetrievalEvaluator(eval_queries, eval_corpus, eval_relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64874a2-f568-4024-8c76-1a5d974c30ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ae401a-f2d2-4537-9986-57d3f499fded",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67c68a11-e08a-42fb-99d0-c6f0da46c103",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7595bffb2f34799bf26f6721065d9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faaa64908d3e4d22a1e21366d7e0fd8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-17 06:31:49 - Save model to output/train_bi-encoder-triplet-sentence-transformers-all-MiniLM-L12-v2-2024-06-17_06-30-11/134\n",
      "2024-06-17 06:31:49 - Information Retrieval Evaluation of the model on the  dataset after epoch 0:\n",
      "2024-06-17 06:36:37 - Queries: 1000\n",
      "2024-06-17 06:36:37 - Corpus: 545818\n",
      "\n",
      "2024-06-17 06:36:37 - Score-Function: cos_sim\n",
      "2024-06-17 06:36:37 - Accuracy@1: 38.20%\n",
      "2024-06-17 06:36:37 - Accuracy@3: 55.30%\n",
      "2024-06-17 06:36:37 - Accuracy@5: 63.60%\n",
      "2024-06-17 06:36:37 - Accuracy@10: 73.30%\n",
      "2024-06-17 06:36:37 - Precision@1: 38.20%\n",
      "2024-06-17 06:36:37 - Precision@3: 32.23%\n",
      "2024-06-17 06:36:37 - Precision@5: 29.80%\n",
      "2024-06-17 06:36:37 - Precision@10: 25.64%\n",
      "2024-06-17 06:36:37 - Recall@1: 5.11%\n",
      "2024-06-17 06:36:37 - Recall@3: 11.23%\n",
      "2024-06-17 06:36:37 - Recall@5: 15.86%\n",
      "2024-06-17 06:36:37 - Recall@10: 25.11%\n",
      "2024-06-17 06:36:37 - MRR@10: 0.4893\n",
      "2024-06-17 06:36:37 - NDCG@10: 0.3255\n",
      "2024-06-17 06:36:37 - MAP@100: 0.2602\n",
      "2024-06-17 06:36:37 - Score-Function: dot_score\n",
      "2024-06-17 06:36:37 - Accuracy@1: 24.60%\n",
      "2024-06-17 06:36:37 - Accuracy@3: 39.90%\n",
      "2024-06-17 06:36:37 - Accuracy@5: 48.50%\n",
      "2024-06-17 06:36:37 - Accuracy@10: 58.90%\n",
      "2024-06-17 06:36:37 - Precision@1: 24.60%\n",
      "2024-06-17 06:36:37 - Precision@3: 20.40%\n",
      "2024-06-17 06:36:37 - Precision@5: 18.38%\n",
      "2024-06-17 06:36:37 - Precision@10: 15.92%\n",
      "2024-06-17 06:36:37 - Recall@1: 3.20%\n",
      "2024-06-17 06:36:37 - Recall@3: 7.01%\n",
      "2024-06-17 06:36:37 - Recall@5: 9.90%\n",
      "2024-06-17 06:36:37 - Recall@10: 15.61%\n",
      "2024-06-17 06:36:37 - MRR@10: 0.3469\n",
      "2024-06-17 06:36:37 - NDCG@10: 0.2037\n",
      "2024-06-17 06:36:37 - MAP@100: 0.1555\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5c9f75057547b38d7794751890181e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-17 06:37:22 - Save model to output/train_bi-encoder-triplet-sentence-transformers-all-MiniLM-L12-v2-2024-06-17_06-30-11/268\n",
      "2024-06-17 06:37:23 - Information Retrieval Evaluation of the model on the  dataset after epoch 1:\n",
      "2024-06-17 06:42:15 - Queries: 1000\n",
      "2024-06-17 06:42:15 - Corpus: 545818\n",
      "\n",
      "2024-06-17 06:42:15 - Score-Function: cos_sim\n",
      "2024-06-17 06:42:15 - Accuracy@1: 39.50%\n",
      "2024-06-17 06:42:15 - Accuracy@3: 58.00%\n",
      "2024-06-17 06:42:15 - Accuracy@5: 65.40%\n",
      "2024-06-17 06:42:15 - Accuracy@10: 74.20%\n",
      "2024-06-17 06:42:15 - Precision@1: 39.50%\n",
      "2024-06-17 06:42:15 - Precision@3: 33.63%\n",
      "2024-06-17 06:42:15 - Precision@5: 30.90%\n",
      "2024-06-17 06:42:15 - Precision@10: 26.46%\n",
      "2024-06-17 06:42:15 - Recall@1: 5.49%\n",
      "2024-06-17 06:42:15 - Recall@3: 11.68%\n",
      "2024-06-17 06:42:15 - Recall@5: 16.51%\n",
      "2024-06-17 06:42:15 - Recall@10: 25.53%\n",
      "2024-06-17 06:42:15 - MRR@10: 0.5047\n",
      "2024-06-17 06:42:15 - NDCG@10: 0.3370\n",
      "2024-06-17 06:42:15 - MAP@100: 0.2717\n",
      "2024-06-17 06:42:15 - Score-Function: dot_score\n",
      "2024-06-17 06:42:15 - Accuracy@1: 24.80%\n",
      "2024-06-17 06:42:15 - Accuracy@3: 40.50%\n",
      "2024-06-17 06:42:15 - Accuracy@5: 47.40%\n",
      "2024-06-17 06:42:15 - Accuracy@10: 59.90%\n",
      "2024-06-17 06:42:15 - Precision@1: 24.80%\n",
      "2024-06-17 06:42:15 - Precision@3: 20.53%\n",
      "2024-06-17 06:42:15 - Precision@5: 18.50%\n",
      "2024-06-17 06:42:15 - Precision@10: 16.35%\n",
      "2024-06-17 06:42:15 - Recall@1: 3.13%\n",
      "2024-06-17 06:42:15 - Recall@3: 7.00%\n",
      "2024-06-17 06:42:15 - Recall@5: 9.99%\n",
      "2024-06-17 06:42:15 - Recall@10: 16.04%\n",
      "2024-06-17 06:42:15 - MRR@10: 0.3483\n",
      "2024-06-17 06:42:15 - NDCG@10: 0.2073\n",
      "2024-06-17 06:42:15 - MAP@100: 0.1599\n",
      "2024-06-17 06:42:15 - Save model to output/train_bi-encoder-triplet-sentence-transformers-all-MiniLM-L12-v2-2024-06-17_06-30-11/268\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=args.warmup_steps,\n",
    "    use_amp=True,\n",
    "    checkpoint_path=model_save_path,\n",
    "    checkpoint_save_steps=len(train_dataloader),\n",
    "    optimizer_params={\"lr\": args.lr},\n",
    "    save_best_model=True,\n",
    "    checkpoint_save_total_limit=2,\n",
    "    evaluator=evaluator,\n",
    "    evaluation_steps=1000,\n",
    "    \n",
    ")\n",
    "\n",
    "# # Save the model\n",
    "# model.save(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e375f7e-7a65-4210-844e-c6bdbacca85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbc66b6-4af4-4f1e-957a-0efefd2053c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
